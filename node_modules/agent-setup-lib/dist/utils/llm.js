"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.Llm = void 0;
const ollama_1 = require("@langchain/ollama");
const openai_1 = require("@langchain/openai");
const groq_1 = require("@langchain/groq");
const anthropic_1 = require("@langchain/anthropic");
class Llm {
    /**
     * Constructs a new Llm instance.
     * @param config - Must include at least the OLLAMA_BASE_URL and, for the respective providers,
     * the required API keys.
     */
    constructor(config) {
        this.chatInstance = null;
        this.chatName = null;
        this.embeddingsInstance = null;
        this.embeddingsName = null;
        this.config = config;
    }
    /**
     * Returns a chat LLM instance along with the provider name.
     * Uses a mapping (use-case style) to instantiate the chosen provider.
     *
     * @param options - Options for the chat LLM including the provider, model, and temperature.
     * @returns An object containing the provider name and the chat LLM instance.
     */
    getChatLlm(options) {
        if (!this.chatInstance) {
            const chatProviders = {
                ollama: () => new ollama_1.ChatOllama({
                    model: options.model || "llama3.2",
                    baseUrl: this.config.OLLAMA_BASE_URL,
                    temperature: options.temperature,
                }),
                openai: () => {
                    if (!this.config.OPENAI_CHAT_API_KEY) {
                        throw new Error("OPENAI_CHAT_API_KEY is required for the OpenAI chat provider.");
                    }
                    return new openai_1.ChatOpenAI({
                        model: options.model || "gpt-4o",
                        temperature: options.temperature,
                        openAIApiKey: this.config.OPENAI_CHAT_API_KEY,
                    });
                },
                groq: () => new groq_1.ChatGroq({
                    model: options.model || "groq-default",
                    temperature: options.temperature,
                }),
                anthropic: () => {
                    if (!this.config.ANTHROPIC_API_KEY) {
                        throw new Error("ANTHROPIC_API_KEY is required for the Anthropic chat provider.");
                    }
                    return new anthropic_1.ChatAnthropic({
                        model: options.model || "claude-v1",
                        temperature: options.temperature,
                        anthropicApiKey: this.config.ANTHROPIC_API_KEY,
                    });
                },
            };
            this.chatInstance = chatProviders[options.provider]();
            this.chatName = options.provider;
        }
        return { name: this.chatName, instance: this.chatInstance };
    }
    /**
     * Returns an embeddings instance along with the provider name.
     * Uses a mapping (use-case style) to instantiate the chosen provider.
     *
     * @param options - Options for embeddings including the provider and model.
     * @returns An object containing the provider name and the embeddings instance.
     */
    getEmbeddings(options) {
        if (!this.embeddingsInstance) {
            const embeddingProviders = {
                ollama: () => new ollama_1.OllamaEmbeddings({
                    model: options.model || "",
                    baseUrl: this.config.OLLAMA_BASE_URL,
                }),
                openai: () => {
                    if (!this.config.OPENAI_EMBEDDINGS_API_KEY) {
                        throw new Error("OPENAI_EMBEDDINGS_API_KEY is required for the OpenAI embeddings provider.");
                    }
                    return new openai_1.OpenAIEmbeddings({
                        model: options.model || "",
                        openAIApiKey: this.config.OPENAI_EMBEDDINGS_API_KEY,
                    });
                },
            };
            this.embeddingsInstance = embeddingProviders[options.provider]();
            this.embeddingsName = options.provider;
        }
        return { name: this.embeddingsName, instance: this.embeddingsInstance };
    }
}
exports.Llm = Llm;
